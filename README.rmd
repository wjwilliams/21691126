---
output:
  md_document:
    variant: markdown_github
always_allow_html: true
---

# Purpose

This is the final README, it is a compilation of all the questions.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')


rm(list = ls()) # Clean your environment:
gc() # garbage collection - It can be useful to call gc after a large object has been removed, as this may prompt R to return memory to the operating system.

#NB load the tidyverse
library(tidyverse)

#Loading all the code from all 5 locations, this enables me to use all the functions that I have created for all of the seperate Questions
list.files('code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question1/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question2/code/', full.names = T, recursive = T)%>% .[grepl('.R', .)]  %>% as.list() %>% walk(~source(.))
list.files('Question3/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question4/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question5/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

```

# Question 1

```{r}
library(tidyverse)
library(xtable)
library(lubridate)
library(glue)
library(ggplot2)
library(cowplot)
library(rmsfuns)

#Source my code/funcrions
list.files('Question/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
#First lets load the data in

covid <- read.csv("Question1/data/Covid/owid-covid-data.csv")
deaths <- read.csv("Question1/data/Covid/Deaths_by_cause.csv")
```

## Africa and Covid
Covid-19 was a global catastrophe and it is no secret that different parts of the world were effected differently. The figures below show the total number of cases and total number of deaths by continent. It was common belief at the start of the pandemic that Africa would be effected the most due to the high levels of poverty, lack of health infrastructure compared to the rest of the world and areas with high population density. These figures show that this was a misconception as Africa has the least amount of cases and second least amount of deaths. Mismeasurement is of course a concern but it is highly unlikely that it would change the results substantially as Oceania is the closest with respect to total cases and they has nearly double the amount of total cases. Again when looking at deaths the gap between Asia and Africa is so large that mismeasurement is not a valid excuse. It would be highly informative to attempt to quantify why this was the case. I am of the opinion that Africans have better immune systems due to the standard of living on the continent that it was easier to fight the virus. South America on the other hand was effected the most and as I show later this can be partially attributed to the the lack of change in hospital facilities.
```{r warning =  FALSE, fig.align = 'center', fig.cap = "Evolution of COVID\\label{Figure1}", fig.ext = 'png', fig.height = 8, fig.width = 7}


ep1 <- evolutionplotter(covid)

ep2 <- evolutionplotter2(covid)

bothplots <- plot_grid(ep1, ep2, ncol = 1)

bothplots
```

## Respitory Deaths before and during Covid
Another idea that recieved a lot of attention during the pandemic was the effect of smoking and the severity of Covid. To investigate this I found the 3 countries with the highest rate of smokers (Russia, Greece and Montenegro) all with nearly 90% of their population being smokers and the 3 countries with the lowest rate of smoking (Ghana, Ethiopia and Nigeria) all with less than 10% of their populations being smokers. This could also be a reason as to why Africa was least effected as they have smaller rate of smokers compared to the rest of the world. The table shows that the death rates due to respitory illness (which is what Covid is) increased at a much higher rate for top smoking countries. This shows that smoking definitely did increase the dangers of Covid.

```{r, results = 'asis'}


SmokerTable <- smoker_death_tabular(covid, Latex = FALSE, CountryList = c("Greece", "Russia", "Montenegro", "Ghana", "Ethiopia", "Nigeria"))

SmokerTable

    
```

## Hospitalisation Facilities and ICU admissions

For this section I chose to use just three continents (Europe, Asia and South America). Europe showd that increased hospitilastion facilities led ICU admissions and in the early stages of 2020 actually helped to reduce admissions. In Asia, it lagged as it was constant until late 2021 which did lead the final wave of admissions. Lastly, South America seemed to do nothing to improve hospital facilities and their beds per thousand of people was constant throughout the whole pandemic which definitely contributed to being effected the worst out of all the continents.
```{r warning =  FALSE, fig.align = 'center', fig.cap = "Evolution of Hospitals\\label{Figure2}", fig.ext = 'png', fig.height = 8, fig.width = 7}

h <- ICU_Plotter(covid)

h

```


# Question 2

```{r}
library(tidyverse)
library(xtable)
library(lubridate)
library(glue)
library(cowplot)

list.files('Question2/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

#read in the data
london <- read.csv("Question2/data/London/london_weather.csv")
UK <- read.csv("Question2/data/London/UKMonthly_Detailed.csv")

#First I need to make sure the date is in the right format using lubridate
weather <- london %>% 
    mutate(date = ymd(date))
```

## Is the weather better in the midlands of England or London?
Let's start with temperature, The graphs below show that not only does London have better weather than the midlands, but the maximum temperature in both places is still colder than Cape town. 

```{r Figure1,  warning =  FALSE, fig.align = 'center', fig.cap = "London Tempreture\\label{Figure1}", fig.ext = 'png', fig.height = 7, fig.width = 10}


tp <-Temp_plotter(weather, place ="London")


#Lets compare this to the midlands where she wants to move
#First letss limit the sample to just the last 50 years
#names(UK) #get the names in the console fot ease of comparison to the pdf doc
temp <- UK %>% 
    mutate(date = ym(DATE)) %>% 
    select(date, TAVG, TMAX, TMIN) %>% 
    rename("mean_temp" ="TAVG", "min_temp" = "TMIN","max_temp" = "TMAX") #rename so we can use the previous function
tp2 <-Temp_plotter(temp, place ="Midlands")

bothplots <- plot_grid(tp, tp2, ncol = 1)

bothplots


    
```

## Is it more sunny or cloudy?
Now that it has been shown that the weather is better in the London than the midlands let's look at whether London is more sunny than cloudy. The graph below shows that its has only been more sunny than cloudy for 1 year (2014) since 1978. Not only that but the rate of sunshine seems to be decreasing over time as well. So it is pretty much colder, more cloudy and more miserable.

```{r Figure2,  warning =  FALSE, fig.align = 'center', fig.cap = "London is getting less and less sunshine \\label{Figure2}", fig.ext = 'png', fig.height = 7, fig.width = 10}


hs<-hist_sun_plotter(weather)
hs
```

## Rain, rain and rain
We all know that Cape Town has winter rain, but that is okay cause that is when it is cold so you will be inside anyway. In London however it seems to be raining all the time. In Cape Town we can enjoy summer because it barely rains but in London its going to be cold in winter, and then in summer it is just going to rain. I hope you find a lovely house if you do move because you are going to be spending most of your time inside.

```{r results= 'asis'}

rt <- raintable(weather, Latex = FALSE)
rt
```


# Question 3


```{r}
library(tidyverse)
library(xtable)
library(lubridate)
library(ggplot2)
library(glue)
library(cowplot)
library(rmsfuns)

#Source my code/funcrions
list.files('Question3/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

#Read in the data
cold <- read.csv("Question3/data/Coldplay_vs_Metallica/Coldplay.csv")
cold <- cold %>% 
    rename("album" = "album_name")
metal <- read.csv("Question3/data/Coldplay_vs_Metallica/Metallica.csv")
spotify <- read.csv("Question3/data/Coldplay_vs_Metallica/Broader_Spotify_Info.csv")
```

# Popularity by album 

The two figures below show that Coldplay's discography is slightly more volatile than Metallica's in terms of popularity but overall are more popular. 
```{r warning =  FALSE, fig.align = 'center', fig.cap = "Coldplay\\label{Figure1}", fig.ext = 'png', fig.height = 10, fig.width = 10}
#Firstly lets make a function to get the boxplots for both bands


  
coldbp<-box_plotter(cold, Band = "Coldplay")
coldbp
```

```{r warning =  FALSE, fig.align = 'center', fig.cap = "Metallics\\label{Figure2}", fig.ext = 'png', fig.height = 10, fig.width = 10}

metalbp<-box_plotter(metal, Band = "Metallica")
metalbp
```

```{r}
#I think Linkin Park is a fantastic example of a Band that has chnaged what they do and are still popular

# linkin <- spotify %>%
#     filter(artist == "Linkin Park") %>%
#     select(energy,)

#Now lets look at how energy relates to popularity
 #unfortunatly there is no popularity score for LINKIN PARK


```
## Components of each Band: What drives Their Popularity?

Now I show the correlation of identifying factors of both bands with popularity. I start with energy and it seems that firstly Coldplay are much more diverse as they have songs ranging from nearly 0 whereas Metallica's songs are clusered close to 1. Coldplay seem to have an optimal energy level of between 0.4 and 0.6 and Metalica is more popular between 0.75 and 1. 

```{r warning =  FALSE, fig.align = 'center', fig.cap = "Metallics\\label{Figure3}", fig.ext = 'png', fig.height = 7, fig.width = 8}
 #now lets look at the factors that can influence the popularity, Metallica is a metal band so i would expect tempo and energy to be a prominant factor whereas i would expect coldplay to rely on energy and liveness, first i need to combine the data

cold1 <- cold %>% 
    mutate(Band = "Coldplay") %>% 
    select(release_date, name, album, popularity, energy, danceability, tempo, valence, Band) %>% 
            filter(!grepl("Remaster", album),!grepl("Box Set", album), !grepl("Live", album), !grepl("Live", name))


metal1 <- metal %>% 
    mutate(Band = "Mettalica") %>% 
    select(release_date, name, album, popularity, energy, danceability, tempo, valence, Band) %>% 
            filter(!grepl("Remaster", album),!grepl("Box Set", album), !grepl("Live", album), !grepl("Live", name))


battle <- bind_rows(cold1, metal1)
    
#Now i want to look at the popularity vs energy and then get different colours and a line for each


ep <- correl_energy_plotter(battle)
ep

```

Next looking at tempo, again Coldplay is more diverse with their songs ranging from 60 beats per minute to over 200 whereas Metallica only ranges from 75 to just under 200. Metallica's popularity increases with Tempo.

```{r warning =  FALSE, fig.align = 'center', fig.cap = "Metallics\\label{Figure4}", fig.ext = 'png', fig.height = 7, fig.width = 8}

tp <-correl_tempo_plotter(battle)
tp
```
Lastly I looked at Valence. 
Valence is a measure of the degree of positive or negative sentiment associated with a particular experience, object, or event, typically represented on a scale from 0 to 1, where 0 indicates negative valence and 1 indicates positive valence. It reflects the subjective assessment of the emotional tone or quality of the subject matter. Coldplay is more popular with lowe levels so their most popular songs are more sad songs and Metalica's popularity increases with valence so their more upbeat songs are more popular on average.

```{r warning =  FALSE, fig.align = 'center', fig.cap = "Metallics\\label{Figure5}", fig.ext = 'png', fig.height = 7, fig.width = 8}
vp <- correl_valence_plotter(battle)
vp
```


##Most popular song by album and year. Both Metallica and Coldplay's most popular songs seem to have more energy through the years. Coldplay's tempo seems to decrease over time wheras Metallica's tempo has been relatibely constant.
```{r results='asis'}


pop_table <- table_popular(battle, Latex = FALSE)
pop_table
```


# Question 4

```{r}
library(tidyverse)
library(lubridate)
library(glue)
library(xtable)
library(RColorBrewer)


#Source my code/funcrions
list.files('Question4/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

#read in the data
credits <- read.csv("Question4/data/netflix/credits.csv")
title <- read.csv("Question4/data/netflix/titles.csv")
```

# Best Actors and Directors

```{r}
#Lets try and merge the data to do this I want to get the credits data into a long format with the row for each movie/series
check<-unique(credits$role)
#There are only actors and directors so I need to differentiate between them 
credit <- credits %>% 
  group_by(id) %>% 
  summarise(actors = paste(name[role == "ACTOR"], collapse = ", "),
            directors = paste(name[role == "DIRECTOR"], collapse = ", "),
            .groups = "drop")

#Now i can left join the credits to the title
netflix <- left_join(title, credit, by = "id")
# Now i have a merged data set with the actors and directors and i want to look at which actors and directors are associated with the top movies
```
Below are tables of actors that on average have the best average critic ratings and audience ratings. It would be beneficial to have any movies that has these actors and directors as they are likely to be the most highest rated movies. 
```{r results='asis'}

toptable <-top_table(netflix, Latex = FALSE)
toptable
```

```{r results='asis'}
#Lets also do it for audience scores

aud_top<-audience_top_table(netflix, Latex = FALSE)
aud_top

```

## Genres to Focus on
Below is a plot of the audience and critic rated most popular movies by genre. There is a line at 6.5 to show movie genres that consistently get good ratings. If you want the best rated genres I would suggest getting historical war movies, documentaries and music movies. If you care more about popularity I would suggest animation, sci-fi fantasy, western and action. I think the best movies to have are war movies as they are the best of both worlds.

```{r warning =  FALSE, fig.align = 'center', fig.cap = "Popularity and Ratings by Grenre\\label{Figure1}", fig.ext = 'png', fig.height = 8, fig.width = 10}


gp<-Genre_plotter(netflix)
gp
```
## Words in descriptions

Lastly I show a wordcloud of the most popular words in descriptions of movies that have a audience rating of more than 7. This shows what the best movies use to market themselves and what the most popular themes among audiences. Clearly movies about love, friends and family are the most popular.

```{r  warning =  FALSE, fig.align = 'center', fig.cap = "Frequency of Words in Top Movie Descriptions\\label{Figure2}", fig.ext = 'png', fig.height = 7, fig.width = 10}

wc<-wordcloud_plotter(netflix)
wc

```


# Question 5
```{r}
library(tidyverse)
library(xtable)
library(lubridate)
library(glue)
library(cowplot)
library(RColorBrewer)
library(viridis)  

list.files('Question5/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

#load in the data
review <- read.csv("Question5/data/googleplay/googleplaystore_user_reviews.csv")
google <- read.csv("Question5/data/googleplay/googleplaystore.csv")


```


## Ratings and Positive Reviews by Category
If you want to create an App it is very important that as soon after its inception it gets as many reviews and ratings as possible but you also want high ratings and positive reviews. This will help your App gain momentum as people are more likely to download your App if it has already been rated and reviewed as it creates a sense of trust. Below I have created the average reviews and positive ratings by category. I limited it to the top 50% of downloads as I wanted to only imvestigate sucessful Apps. From this i would recommend an App under the Art and Design category as those apps get rated the most highly and have the most positive reviews. 

```{r}
#First lets get a date
google <-google %>% 
    mutate(date = mdy(Last.Updated))




#Lets see the average installs and then we only want to look at the top half
#we first need to get the installs to dbl
downloads <- google %>% 
    group_by(Type)%>% 
    mutate(download = as.numeric(gsub("[,\\+]", "", Installs))) %>% 
    summarise(avg_down = mean(download))
#the average download is 9387454 for free apps  and 77439.49 for paid apps but we only want to look at above average apps
good_apps<- google %>% 
    filter(!is.na(Installs), !is.na(Type)) %>% 
    mutate(download = as.numeric(gsub("[,\\+]", "", Installs))) %>% 
    filter(ifelse(Type == "Free", download > 8657758, download >  77439.49))

#now lets combine the datasets
# unique(review$Sentiment)

reviews <- review %>% 
    group_by(App) %>% 
    filter(!grepl("nan", Sentiment), !is.na(Sentiment)) %>% 
    summarise(pos_sentiment = sum(Sentiment == "Positive")/n() ) 

combined <- left_join(good_apps, reviews, by = "App") %>% 
    filter(!is.na(pos_sentiment))

```


```{r warning =  FALSE, fig.align = 'center', fig.cap = "Ratings and Reviews by Category\\label{Figure1}", fig.ext = 'png', fig.height = 10, fig.width = 10}


cb<-category_barplotter(combined)
cb
```
## Does App Size affect Downloads and Ratings?
The next step in the optimization process of the app is determining how large it should be. It os a highly common in the modern era to delete Apps that are rather large to ensure your device has sufficient memory. The table below shows the correlation of size with downloads and ratings this information can help evaluate the trade-off between size, functionality and scope of your App. Following from my recommendation above, Art and design applications are downloaded more if they are larger and there is no large correlation between the Rating and the size so I would recommend ensuring functionality and scope of the App as the size is of little concern as people do not seem deterred from downloading apps in this genre if they are large.
```{r results='asis'}


ct<- correl_tabler(google, Latex = FALSE)
ct
    
```



